{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fec28a51",
   "metadata": {},
   "source": [
    "## üîç Natural Language Processing (NLP): Foundational Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980e9106",
   "metadata": {},
   "source": [
    "### üéØ Definition:\n",
    "Natural Language Processing (NLP) is a subfield of Artificial Intelligence (AI) and Linguistics that focuses on enabling machines to understand, interpret, and generate human language.\n",
    "\n",
    "### üìö Core Components:\n",
    "| Component               | Description                                                                                      |\n",
    "| ----------------------- | ------------------------------------------------------------------------------------------------ |\n",
    "| **Text Preprocessing**  | Tokenization, stemming, lemmatization, stop word removal, lowercasing, etc.                      |\n",
    "| **Text Representation** | Bag of Words (BoW), TF-IDF, Word Embeddings (Word2Vec, GloVe), Contextual embeddings (BERT, GPT) |\n",
    "| **Syntax & Parsing**    | Part-of-speech tagging, dependency parsing, constituency parsing                                 |\n",
    "| **Semantics**           | Named Entity Recognition (NER), word sense disambiguation                                        |\n",
    "| **Pragmatics**          | Understanding context, irony, and implied meaning                                                |\n",
    "\n",
    "### üì¶ Common NLP Tasks:\n",
    "| Task                               | Description                                                    |\n",
    "| ---------------------------------- | -------------------------------------------------------------- |\n",
    "| **Text Classification**            | Spam detection, sentiment analysis, topic classification       |\n",
    "| **Named Entity Recognition (NER)** | Extracting people, places, organizations from text             |\n",
    "| **Part-of-Speech Tagging**         | Identifying grammatical roles (noun, verb, adjective, etc.)    |\n",
    "| **Machine Translation**            | Translating text from one language to another                  |\n",
    "| **Text Summarization**             | Extractive and abstractive methods to summarize content        |\n",
    "| **Question Answering**             | Answering queries from unstructured or structured content      |\n",
    "| **Text Generation**                | Producing human-like text (e.g., chatbots, content generation) |\n",
    "\n",
    "\n",
    "### üíº Industry Use Cases\n",
    "| Domain               | Use Case                                                                |\n",
    "| -------------------- | ----------------------------------------------------------------------- |\n",
    "| **Finance**          | Sentiment analysis of market news, fraud detection from email/chat logs |\n",
    "| **Healthcare**       | Extracting key terms from clinical notes, medical report summarization  |\n",
    "| **E-Commerce**       | Product recommendation based on reviews, intelligent search systems     |\n",
    "| **Legal**            | Contract analysis, case summarization, legal document classification    |\n",
    "| **Customer Service** | Chatbots, ticket routing, intent classification                         |\n",
    "| **Marketing**        | Brand monitoring, personalized messaging, ad targeting                  |\n",
    "\n",
    "### üõ†Ô∏è Tools & Libraries\n",
    "| Library/Tool          | Description                                                                 |\n",
    "| --------------------- | --------------------------------------------------------------------------- |\n",
    "| **NLTK**              | Natural Language Toolkit, a suite of libraries for NLP tasks in Python      |\n",
    "| **spaCy**             | Industrial-strength NLP library for Python, optimized for performance      |\n",
    "| **Transformers**      | Hugging Face library for state-of-the-art NLP models (BERT, GPT, etc.)     |\n",
    "| **Gensim**            | Topic modeling and document similarity, supports Word2Vec and Doc2Vec     |\n",
    "| **TextBlob**          | Simplified text processing, built on NLTK and Pattern                      |\n",
    "| **OpenNLP**           | Apache's machine learning-based toolkit for processing natural language    |\n",
    "| **Stanford NLP**      | Java-based library for various NLP tasks, including parsing and NER       |\n",
    "\n",
    "### üìñ Further Reading\n",
    "- [Speech and Language Processing (3rd Edition)](https://web.stanford.edu/~jurafsky/slp3/)\n",
    "- [Natural Language Processing with Python](https://www.nltk.org/book/)\n",
    "- [Introduction to Natural Language Processing](https://www.coursera.org/learn/natural-language-processing)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220be71b",
   "metadata": {},
   "source": [
    "### üìò Common NLP Terminologies\n",
    "| Term                                                     | Definition                                                                                                           |\n",
    "| -------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Corpus**                                               | A large and structured set of texts. It serves as the dataset for NLP tasks.                                         |\n",
    "| **Token**                                                | A single unit of text, typically a word or punctuation mark.                                                         |\n",
    "| **Tokenization**                                         | The process of splitting text into individual tokens (words, subwords, or characters).                               |\n",
    "| **Stop Words**                                           | Common words (e.g., ‚Äúis‚Äù, ‚Äúthe‚Äù, ‚Äúa‚Äù) that are often removed from text as they carry little semantic meaning.        |\n",
    "| **Stemming**                                             | The process of reducing a word to its base/root form (e.g., ‚Äúplaying‚Äù ‚Üí ‚Äúplay‚Äù).                                     |\n",
    "| **Lemmatization**                                        | Similar to stemming, but more linguistically accurate, considering context and vocabulary (e.g., ‚Äúbetter‚Äù ‚Üí ‚Äúgood‚Äù). |\n",
    "| **POS Tagging (Part-of-Speech Tagging)**                 | Assigning each word a grammatical category such as noun, verb, adjective, etc.                                       |\n",
    "| **Named Entity Recognition (NER)**                       | Identifying and classifying entities in text (like person names, organizations, locations, dates).                   |\n",
    "| **Bag of Words (BoW)**                                   | A text representation method where each word is treated as a feature, ignoring grammar and order.                    |\n",
    "| **TF-IDF (Term Frequency ‚Äì Inverse Document Frequency)** | A statistical method that evaluates how important a word is to a document in a collection.                           |\n",
    "| **Word Embedding**                                       | A dense vector representation of words capturing semantic relationships (e.g., Word2Vec, GloVe).                     |\n",
    "| **n-gram**                                               | A contiguous sequence of 'n' items (usually words or characters) from a given text (e.g., bigram, trigram).          |\n",
    "| **Cosine Similarity**                                    | A metric to measure similarity between two text vectors.                                                             |\n",
    "| **Text Classification**                                  | Assigning predefined categories to text (e.g., spam or not spam).                                                    |\n",
    "| **Sentiment Analysis**                                   | Identifying and categorizing opinions expressed in text as positive, negative, or neutral.                           |\n",
    "| **Topic Modeling**                                       | Unsupervised technique to discover hidden thematic structure in text (e.g., LDA - Latent Dirichlet Allocation).      |\n",
    "| **Parsing**                                              | Analyzing the syntactic structure of a sentence (e.g., constituency or dependency parsing).                          |\n",
    "| **Language Modeling**                                    | Predicting the next word or sequence of words in a sentence (e.g., GPT, BERT).                                       |\n",
    "| **Perplexity**                                           | A measurement of how well a probabilistic language model predicts a sample; lower is better.                         |\n",
    "| **Sequence Labeling**                                    | Assigning labels to each token in a sequence (e.g., POS tagging, NER).                                               |\n",
    "| **Transformer**                                          | Deep learning model architecture based on attention mechanisms (used in BERT, GPT, etc.).                            |\n",
    "| **Attention Mechanism**                                  | A method that allows the model to focus on relevant parts of the input sequence while making predictions.            |\n",
    "| **Contextual Embedding**                                 | Word embeddings that consider surrounding context, used in models like BERT.                                         |\n",
    "| **Fine-tuning**                                          | Adapting a pre-trained NLP model to a specific downstream task using task-specific data.                             |\n",
    "| **Zero-shot / Few-shot Learning**                        | Performing NLP tasks with zero or minimal task-specific training examples.                                           |\n",
    "| **Prompt Engineering**                                   | Designing effective input prompts to guide the behavior of language models (especially in generative AI).            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfa0140",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
