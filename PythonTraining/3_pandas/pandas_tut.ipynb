{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7a050f1",
   "metadata": {},
   "source": [
    "## Pandas: Theoretical Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e4fafe",
   "metadata": {},
   "source": [
    "Pandas is an open-source, high-performance Python library designed for data manipulation, data analysis, and data cleaning. It provides data structures and functions needed to work seamlessly with structured (tabular, multidimensional, heterogeneous) and time-series data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd456d32",
   "metadata": {},
   "source": [
    "#### Key Features\n",
    "| Feature                   | Description                                                           |\n",
    "| ------------------------- | --------------------------------------------------------------------- |\n",
    "| **Data Structures**       | `Series` (1D) and `DataFrame` (2D)                                    |\n",
    "| **Handling Missing Data** | Built-in support using `NaN`, `fillna()`, `dropna()`                  |\n",
    "| **Flexible Indexing**     | Label-based (`.loc`) and position-based (`.iloc`) indexing            |\n",
    "| **Data Alignment**        | Automatic data alignment in operations                                |\n",
    "| **File I/O**              | Read/write support for formats such as CSV, Excel, JSON, SQL, Parquet |\n",
    "| **GroupBy Operations**    | Powerful grouping and aggregation using `groupby()`                   |\n",
    "| **Time Series Support**   | Tools for resampling, time shifting, and date parsing                 |\n",
    "| **Vectorized Operations** | Efficient operations across entire datasets (NumPy-based)             |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ea8038",
   "metadata": {},
   "source": [
    "#### Core Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83d29daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Series - One-dimensional labeled array.\n",
    "## Can hold data of any type (integers, strings, floats, Python objects).\n",
    "\n",
    "import pandas as pd\n",
    "s = pd.Series([10, 20, 30], index=['a', 'b', 'c'])\n",
    "\n",
    "## 2. DataFrame - Two-dimensional labeled data structure with columns of potentially different types.\n",
    "## Think of it as an in-memory SQL table or an Excel spreadsheet.\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob'],\n",
    "    'Age': [25, 30]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b8dc4c",
   "metadata": {},
   "source": [
    "#### Core Functionalities\n",
    "| Operation         | Method                                     | Example                       |\n",
    "| ----------------- | ------------------------------------------ | ----------------------------- |\n",
    "| **Read data**     | `read_csv`, `read_excel`, `read_json`      | `pd.read_csv('file.csv')`     |\n",
    "| **View data**     | `head()`, `tail()`, `info()`, `describe()` | `df.head()`                   |\n",
    "| **Selection**     | `df['col']`, `df.loc[]`, `df.iloc[]`       | `df.loc[0, 'Age']`            |\n",
    "| **Filtering**     | Conditional indexing                       | `df[df['Age'] > 25]`          |\n",
    "| **Add column**    | Assignment                                 | `df['Salary'] = [5000, 6000]` |\n",
    "| **Drop column**   | `drop()`                                   | `df.drop('Age', axis=1)`      |\n",
    "| **Aggregation**   | `mean()`, `sum()`, `groupby()`             | `df.groupby('Dept').mean()`   |\n",
    "| **Sort**          | `sort_values()`                            | `df.sort_values('Age')`       |\n",
    "| **Null handling** | `isnull()`, `fillna()`, `dropna()`         | `df.fillna(0)`                |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfab11ad",
   "metadata": {},
   "source": [
    "#### Use Cases in AI / ML Pipelines\n",
    "| Phase                               | Role of Pandas                                                |\n",
    "| ----------------------------------- | ------------------------------------------------------------- |\n",
    "| **Data Ingestion**                  | Load structured data from various sources                     |\n",
    "| **Data Cleaning**                   | Handle missing values, remove duplicates                      |\n",
    "| **Feature Engineering**             | Create new features, encode categorical data                  |\n",
    "| **Exploratory Data Analysis (EDA)** | Descriptive statistics, visualization with seaborn/matplotlib |\n",
    "| **Preprocessing**                   | Normalize/standardize, binning, transformation                |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27f5a2f",
   "metadata": {},
   "source": [
    "#### Interoperability\n",
    "Pandas ↔ NumPy: Pandas is built on NumPy; arrays can be interchanged.\n",
    "\n",
    "Pandas ↔ Scikit-learn: Pass DataFrames directly for ML model inputs.\n",
    "\n",
    "Pandas ↔ Matplotlib/Seaborn: Visualization libraries accept DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003ca653",
   "metadata": {},
   "source": [
    "#### Installation\n",
    "pip install pandas\n",
    "\n",
    "pip install pandas==1.5.3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98e6bad",
   "metadata": {},
   "source": [
    "### Pandas CSV / Excel I/O & DataFrame Operations — Syntax & Explanation Table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf342c1",
   "metadata": {},
   "source": [
    "#### 1. File Reading (Input)\n",
    "| **Function**               | **Syntax**                                         | **Description**                  |\n",
    "| -------------------------- | -------------------------------------------------- | -------------------------------- |\n",
    "| Read CSV                   | `pd.read_csv('file.csv')`                          | Load a CSV file into a DataFrame |\n",
    "| Read CSV with delimiter    | `pd.read_csv('file.csv', sep=';')`                 | Specify custom delimiter         |\n",
    "| Read Excel                 | `pd.read_excel('file.xlsx')`                       | Load Excel file                  |\n",
    "| Read specific sheet        | `pd.read_excel('file.xlsx', sheet_name='Sheet1')`  | Read specific Excel sheet        |\n",
    "| Read with column names     | `pd.read_csv('file.csv', names=['A', 'B'])`        | Set custom column names          |\n",
    "| Read only selected columns | `pd.read_csv('file.csv', usecols=['Name', 'Age'])` | Read specific columns            |\n",
    "| Read with index column     | `pd.read_csv('file.csv', index_col='ID')`          | Set column as index              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f77db99",
   "metadata": {},
   "source": [
    "####  2. File Writing (Output)\n",
    "| **Function**                   | **Syntax**                                       | **Description**               |\n",
    "| ------------------------------ | ------------------------------------------------ | ----------------------------- |\n",
    "| Write to CSV                   | `df.to_csv('output.csv')`                        | Export to CSV including index |\n",
    "| Write to CSV (no index)        | `df.to_csv('output.csv', index=False)`           | Exclude index in export       |\n",
    "| Write to Excel                 | `df.to_excel('output.xlsx')`                     | Export DataFrame to Excel     |\n",
    "| Write Excel specific sheet     | `df.to_excel('output.xlsx', sheet_name='Sales')` | Custom sheet name             |\n",
    "| Write with null as custom text | `df.to_csv('out.csv', na_rep='N/A')`             | Replace NaN with text         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b13681f",
   "metadata": {},
   "source": [
    "#### 3. Viewing & Inspecting Data\n",
    "| **Function**        | **Syntax**      | **Description**          |\n",
    "| ------------------- | --------------- | ------------------------ |\n",
    "| View top rows       | `df.head()`     | First 5 rows             |\n",
    "| View bottom rows    | `df.tail(10)`   | Last 10 rows             |\n",
    "| Data dimensions     | `df.shape`      | Tuple of (rows, columns) |\n",
    "| Column names        | `df.columns`    | All column headers       |\n",
    "| Data types & nulls  | `df.info()`     | Summary of structure     |\n",
    "| Statistical summary | `df.describe()` | Mean, std, min, max etc. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d972adc4",
   "metadata": {},
   "source": [
    "####  4. Selection & Filtering\n",
    "| **Task**                | **Syntax**                                    | **Description**      |\n",
    "| ----------------------- | --------------------------------------------- | -------------------- |\n",
    "| Select column           | `df['Age']`                                   | Get column as Series |\n",
    "| Select multiple columns | `df[['Age', 'Salary']]`                       | Return as DataFrame  |\n",
    "| Select row by index     | `df.loc[0]`                                   | By label             |\n",
    "| Select row by position  | `df.iloc[0]`                                  | By index             |\n",
    "| Conditional filter      | `df[df['Age'] > 30]`                          | Filter rows          |\n",
    "| Compound condition      | `df[(df['Age']>30) & (df['Gender']=='Male')]` | Combine filters      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55810479",
   "metadata": {},
   "source": [
    "####  5. Aggregation & Grouping\n",
    "| **Operation**        | **Syntax**                               | **Description**  |\n",
    "| -------------------- | ---------------------------------------- | ---------------- |\n",
    "| Column mean          | `df['Salary'].mean()`                    | Average salary   |\n",
    "| Grouping             | `df.groupby('Dept')['Salary'].sum()`     | Sum by group     |\n",
    "| Multiple aggregation | `df.agg({'Age':'mean', 'Salary':'max'})` | Multiple metrics |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd765d96",
   "metadata": {},
   "source": [
    "#### 6. Modifying Data\n",
    "| **Task**       | **Syntax**                                   | **Description**       |\n",
    "| -------------- | -------------------------------------------- | --------------------- |\n",
    "| Add column     | `df['Bonus'] = df['Salary'] * 0.10`          | Derived column        |\n",
    "| Update values  | `df.loc[df['Dept']=='HR', 'Salary'] += 1000` | Conditional update    |\n",
    "| Rename columns | `df.rename(columns={'old':'new'})`           | Rename headers        |\n",
    "| Replace values | `df.replace('Sales', 'Marketing')`           | Replace string/values |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4291e8ae",
   "metadata": {},
   "source": [
    "#### 7. Cleaning & Handling Nulls\n",
    "| **Task**              | **Syntax**                  | **Description**            |\n",
    "| --------------------- | --------------------------- | -------------------------- |\n",
    "| Null count            | `df.isnull().sum()`         | Missing value count        |\n",
    "| Drop nulls            | `df.dropna()`               | Remove rows with NaN       |\n",
    "| Fill nulls with value | `df.fillna(0)`              | Replace NaN with 0         |\n",
    "| Forward fill          | `df.fillna(method='ffill')` | Propagate last valid value |\n",
    "| Drop duplicates       | `df.drop_duplicates()`      | Remove duplicate rows      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc25193a",
   "metadata": {},
   "source": [
    "####  8. Sorting, Indexing & Reset\n",
    "| **Task**        | **Syntax**                                     | **Description**     |\n",
    "| --------------- | ---------------------------------------------- | ------------------- |\n",
    "| Sort values     | `df.sort_values(by='Salary')`                  | Ascending           |\n",
    "| Sort descending | `df.sort_values(by='Salary', ascending=False)` | Descending          |\n",
    "| Reset index     | `df.reset_index(drop=True)`                    | Rebuild index       |\n",
    "| Set index       | `df.set_index('ID')`                           | Change index column |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99feff9b",
   "metadata": {},
   "source": [
    "#### 9. Merging / Joining / Concatenating\n",
    "| **Task**     | **Syntax**                                 | **Description**        |\n",
    "| ------------ | ------------------------------------------ | ---------------------- |\n",
    "| Merge on key | `pd.merge(df1, df2, on='ID')`              | Inner join by default  |\n",
    "| Left join    | `pd.merge(df1, df2, on='ID', how='left')`  | Keep all rows from df1 |\n",
    "| Outer join   | `pd.merge(df1, df2, on='ID', how='outer')` | Union of both          |\n",
    "| Concatenate  | `pd.concat([df1, df2])`                    | Stack vertically       |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3ace34",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
