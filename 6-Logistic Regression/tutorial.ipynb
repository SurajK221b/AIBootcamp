{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43c55e8d",
   "metadata": {},
   "source": [
    "## Logistic Regression ‚Äì Overview\n",
    "| Category       | Details                                                                                                                                                     |\n",
    "| -------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Definition** | A **supervised learning algorithm** used for binary classification problems. It estimates the probability that a given input belongs to a certain class.    |\n",
    "| **Key Idea**   | Instead of predicting continuous output (like linear regression), it predicts **probabilities** using a **sigmoid function** to map values between 0 and 1. |\n",
    "| **Use Cases**  | Email Spam Detection, Credit Card Fraud Detection, Customer Churn Prediction, Disease Diagnosis (yes/no)                                                    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac751fc",
   "metadata": {},
   "source": [
    "### üìà Mathematical Foundation\n",
    "| Component               | Explanation                                                                                                                                        |\n",
    "| ----------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Hypothesis Function** | $h_\\theta(x) = \\frac{1}{1 + e^{-\\theta^T x}}$                                                                                                      |\n",
    "| **Cost Function**       | Cross-Entropy Loss: <br> $-\\frac{1}{m} \\sum_{i=1}^{m} \\left[ y^{(i)} \\log(h_\\theta(x^{(i)})) + (1 - y^{(i)}) \\log(1 - h_\\theta(x^{(i)})) \\right] $ |\n",
    "| **Optimization**        | Gradient Descent / Stochastic Gradient Descent                                                                                                     |\n",
    "| **Decision Boundary**   | If $h_\\theta(x) \\geq 0.5 \\Rightarrow y = 1$, else $y = 0$                                                                                          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60ba0f0",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Python Implementation Example (Using scikit-learn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cf4124b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X = iris.data[:100, :2]  # Taking 2 features for simplicity and binary target\n",
    "y = iris.target[:100]    # Binary classification (setosa vs versicolor)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b5f3ee",
   "metadata": {},
   "source": [
    "### üìä Evaluation Metrics for Classification\n",
    "| Metric                   | Formula / Use                                                                             |\n",
    "| ------------------------ | ----------------------------------------------------------------------------------------- |\n",
    "| **Accuracy**             | $\\frac{TP + TN}{TP + TN + FP + FN}$                                                       |\n",
    "| **Precision**            | $\\frac{TP}{TP + FP}$                                                                      |\n",
    "| **Recall (Sensitivity)** | $\\frac{TP}{TP + FN}$                                                                      |\n",
    "| **F1-Score**             | Harmonic mean of Precision & Recall                                                       |\n",
    "| **AUC-ROC**              | Probability that the model ranks a random positive instance higher than a random negative |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d17b877",
   "metadata": {},
   "source": [
    "### üß† Interview Questions ‚Äì Logistic Regression\n",
    "| Level        | Question                                                        | Expected Answer                                                                                |\n",
    "| ------------ | --------------------------------------------------------------- | ---------------------------------------------------------------------------------------------- |\n",
    "| Beginner     | What is logistic regression?                                    | A classification algorithm that uses sigmoid function to predict binary outcomes.              |\n",
    "| Intermediate | Why use sigmoid instead of linear output?                       | Because it maps any real-valued number into the range (0, 1) for probability interpretation.   |\n",
    "| Intermediate | Explain the cost function in logistic regression.               | Uses cross-entropy (log loss) to penalize wrong predictions more harshly.                      |\n",
    "| Advanced     | What are the assumptions of logistic regression?                | Linearity between independent variables and log-odds, no multicollinearity, large sample size. |\n",
    "| Advanced     | Can logistic regression be used for multi-class classification? | Yes, via One-vs-Rest (OvR) or Softmax (for multinomial logistic regression).                   |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df98975b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
